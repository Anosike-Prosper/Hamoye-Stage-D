{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.status.busy": "2021-10-19T10:13:01.376556Z",
     "iopub.status.idle": "2021-10-19T10:13:01.377734Z",
     "shell.execute_reply": "2021-10-19T10:13:01.377501Z",
     "shell.execute_reply.started": "2021-10-19T10:13:01.377472Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T10:14:18.76198Z",
     "iopub.status.busy": "2021-10-19T10:14:18.761284Z",
     "iopub.status.idle": "2021-10-19T10:14:18.767317Z",
     "shell.execute_reply": "2021-10-19T10:14:18.766307Z",
     "shell.execute_reply.started": "2021-10-19T10:14:18.76194Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T10:14:19.440098Z",
     "iopub.status.busy": "2021-10-19T10:14:19.439419Z",
     "iopub.status.idle": "2021-10-19T10:14:19.51294Z",
     "shell.execute_reply": "2021-10-19T10:14:19.512232Z",
     "shell.execute_reply.started": "2021-10-19T10:14:19.440057Z"
    }
   },
   "outputs": [],
   "source": [
    "#Reading the training data that contains the image names and tags from the directory\n",
    "train_classes = pd.read_csv('../input/planets-dataset/planet/planet/train_classes.csv')\n",
    "train_classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T10:14:21.019043Z",
     "iopub.status.busy": "2021-10-19T10:14:21.018477Z",
     "iopub.status.idle": "2021-10-19T10:14:21.069504Z",
     "shell.execute_reply": "2021-10-19T10:14:21.068735Z",
     "shell.execute_reply.started": "2021-10-19T10:14:21.019009Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = set()\n",
    "def splitting_tags(tags):\n",
    "    for tag in tags.split():\n",
    "        labels.add(tag)\n",
    "\n",
    "#we redefine the train_classes by creating a copy of it so as not to overwrite the existing one. \n",
    "#so a copy of the train classes is stored in the variable train_classes1, we convert labels which is a set to a list.\n",
    "train_classes1 = train_classes.copy()\n",
    "train_classes1['tags'].apply(splitting_tags)\n",
    "labels = list(labels)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T10:14:22.187054Z",
     "iopub.status.busy": "2021-10-19T10:14:22.186304Z",
     "iopub.status.idle": "2021-10-19T10:14:22.202034Z",
     "shell.execute_reply": "2021-10-19T10:14:22.201251Z",
     "shell.execute_reply.started": "2021-10-19T10:14:22.187019Z"
    }
   },
   "outputs": [],
   "source": [
    "#assert  that the length of the dataframe is the same as the shape\n",
    "assert len(train_classes1['image_name'].unique()) == train_classes1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T10:14:23.044275Z",
     "iopub.status.busy": "2021-10-19T10:14:23.043779Z",
     "iopub.status.idle": "2021-10-19T10:14:23.837621Z",
     "shell.execute_reply": "2021-10-19T10:14:23.836784Z",
     "shell.execute_reply.started": "2021-10-19T10:14:23.04423Z"
    }
   },
   "outputs": [],
   "source": [
    "##One hot encoding is performed on the labels in train classes\n",
    "for tag in labels:\n",
    "    train_classes1[tag] = train_classes1['tags'].apply(lambda x: 1 if tag in x.split() else 0)\n",
    "    \n",
    "## adding .jpg extension to the column image_name so as to have same name format as the image files\n",
    "train_classes1['image_name'] = train_classes1['image_name'].apply(lambda x: '{}.jpg'.format(x))\n",
    "train_classes1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T10:14:24.584052Z",
     "iopub.status.busy": "2021-10-19T10:14:24.583361Z",
     "iopub.status.idle": "2021-10-19T10:14:24.589336Z",
     "shell.execute_reply": "2021-10-19T10:14:24.588558Z",
     "shell.execute_reply.started": "2021-10-19T10:14:24.584013Z"
    }
   },
   "outputs": [],
   "source": [
    "#importing tensorflow libraries for training the dataset\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T10:14:26.211115Z",
     "iopub.status.busy": "2021-10-19T10:14:26.210491Z",
     "iopub.status.idle": "2021-10-19T10:14:26.215055Z",
     "shell.execute_reply": "2021-10-19T10:14:26.213943Z",
     "shell.execute_reply.started": "2021-10-19T10:14:26.211076Z"
    }
   },
   "outputs": [],
   "source": [
    "#defining the columns, that is the labels that were newly added to the train_classes via hot encoding.\n",
    "columns = list(train_classes1.columns[2:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T10:14:26.943672Z",
     "iopub.status.busy": "2021-10-19T10:14:26.942972Z",
     "iopub.status.idle": "2021-10-19T10:14:26.950304Z",
     "shell.execute_reply": "2021-10-19T10:14:26.949407Z",
     "shell.execute_reply.started": "2021-10-19T10:14:26.943633Z"
    }
   },
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T10:14:28.071474Z",
     "iopub.status.busy": "2021-10-19T10:14:28.071188Z",
     "iopub.status.idle": "2021-10-19T10:14:28.07829Z",
     "shell.execute_reply": "2021-10-19T10:14:28.077319Z",
     "shell.execute_reply.started": "2021-10-19T10:14:28.071443Z"
    }
   },
   "outputs": [],
   "source": [
    "def fbeta(y_true, y_pred, beta = 2, epsilon = 1e-4):\n",
    "    \n",
    "    beta_squared = beta**2\n",
    "    \n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(tf.greater(tf.cast(y_pred, tf.float32), tf.constant(0.5)), tf.float32)\n",
    "    \n",
    "    tp = tf.reduce_sum(y_true * y_pred, axis = 1)\n",
    "    fp = tf.reduce_sum(y_pred, axis = 1) - tp\n",
    "    fn = tf.reduce_sum(y_true, axis = 1) - tp\n",
    "    \n",
    "    precision = tp/(tp+fp+epsilon)\n",
    "    recall = tp/(tp+fn+epsilon)\n",
    "    \n",
    "    fb = (1+beta_squared)*precision*recall / (beta_squared*precision+recall+epsilon)\n",
    "    return fb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T10:14:29.895359Z",
     "iopub.status.busy": "2021-10-19T10:14:29.894655Z",
     "iopub.status.idle": "2021-10-19T10:14:29.902578Z",
     "shell.execute_reply": "2021-10-19T10:14:29.901871Z",
     "shell.execute_reply.started": "2021-10-19T10:14:29.89532Z"
    }
   },
   "outputs": [],
   "source": [
    "#define a function for accuracy for multi_label classification\n",
    "def multi_label_acc(y_true, y_pred, epsilon = 1e-4):\n",
    "    \n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(tf.greater(tf.cast(y_pred, tf.float32), tf.constant(0.5)), tf.float32)\n",
    "    \n",
    "    tp = tf.reduce_sum(y_true * y_pred, axis = 1)\n",
    "    fp = tf.reduce_sum(y_pred, axis = 1) - tp\n",
    "    fn = tf.reduce_sum(y_true, axis = 1) - tp\n",
    "    \n",
    "    y_true = tf.cast(y_true, tf.bool)\n",
    "    y_pred = tf.cast(y_pred, tf.bool)\n",
    "        \n",
    "    tn = tf.reduce_sum(tf.cast(tf.logical_not(y_true), tf.float32) * tf.cast(tf.logical_not(y_pred), tf.float32), \n",
    "                       axis = 1)\n",
    "    return (tp+tn)/(tp+tn+fp+fn+epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T10:14:32.121966Z",
     "iopub.status.busy": "2021-10-19T10:14:32.121265Z",
     "iopub.status.idle": "2021-10-19T10:14:32.133936Z",
     "shell.execute_reply": "2021-10-19T10:14:32.133268Z",
     "shell.execute_reply.started": "2021-10-19T10:14:32.121927Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_shape=(128, 128, 3)))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(17, activation='sigmoid'))\n",
    "\n",
    "    opt = Adam(lr=1e-4)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              # We NEED binary here, since categorical_crossentropy l1 norms the output before calculating loss.\n",
    "                  optimizer=opt,\n",
    "              metrics=[multi_label_acc, fbeta])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T10:14:33.670757Z",
     "iopub.status.busy": "2021-10-19T10:14:33.67023Z",
     "iopub.status.idle": "2021-10-19T10:14:33.675294Z",
     "shell.execute_reply": "2021-10-19T10:14:33.674345Z",
     "shell.execute_reply.started": "2021-10-19T10:14:33.670716Z"
    }
   },
   "outputs": [],
   "source": [
    "#modelcheckpoint is set to monitor the model using validation fbeta score and save the best only\n",
    "save_best_check_point = ModelCheckpoint(filepath = 'best_model.hdf5', monitor = 'val_fbeta', mode = 'max',\n",
    "                                       save_best_only = True, save_weights_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T10:14:34.583305Z",
     "iopub.status.busy": "2021-10-19T10:14:34.582759Z",
     "iopub.status.idle": "2021-10-19T10:15:09.74632Z",
     "shell.execute_reply": "2021-10-19T10:15:09.745555Z",
     "shell.execute_reply.started": "2021-10-19T10:14:34.583264Z"
    }
   },
   "outputs": [],
   "source": [
    "train_image_gen = ImageDataGenerator(rescale = 1/255, validation_split = 0.2)\n",
    "\n",
    "#generating train data generator which is 80% of the train dataset\n",
    "\n",
    "train_generator = train_image_gen.flow_from_dataframe(dataframe=train_classes1,\n",
    "                                                directory =\"../input/planets-dataset/planet/planet/train-jpg\",  \n",
    "                                                x_col=\"image_name\", y_col=columns, subset=\"training\", \n",
    "                                                batch_size=16,seed=2021, shuffle=True, \n",
    "                                                class_mode=\"raw\", target_size=(128,128))\n",
    "\n",
    "#generating validation data which is expected to be 20% of the train dataset since validation split is 0.2\n",
    "val_generator = train_image_gen.flow_from_dataframe(dataframe=train_classes1,\n",
    "                                                directory =\"../input/planets-dataset/planet/planet/train-jpg\",  \n",
    "                                                x_col=\"image_name\", y_col=columns, subset=\"validation\", \n",
    "                                                batch_size=16,seed=2021, shuffle=True, \n",
    "                                                class_mode=\"raw\", target_size=(128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T10:15:09.74855Z",
     "iopub.status.busy": "2021-10-19T10:15:09.747823Z",
     "iopub.status.idle": "2021-10-19T10:15:09.753169Z",
     "shell.execute_reply": "2021-10-19T10:15:09.752437Z",
     "shell.execute_reply.started": "2021-10-19T10:15:09.748488Z"
    }
   },
   "outputs": [],
   "source": [
    "step_train_size = int(np.ceil(train_generator.samples / train_generator.batch_size))\n",
    "step_val_size = int(np.ceil(val_generator.samples / val_generator.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T10:15:09.754731Z",
     "iopub.status.busy": "2021-10-19T10:15:09.754453Z",
     "iopub.status.idle": "2021-10-19T10:15:12.284039Z",
     "shell.execute_reply": "2021-10-19T10:15:12.283359Z",
     "shell.execute_reply.started": "2021-10-19T10:15:09.754694Z"
    }
   },
   "outputs": [],
   "source": [
    "model1 = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T10:15:12.286426Z",
     "iopub.status.busy": "2021-10-19T10:15:12.286005Z",
     "iopub.status.idle": "2021-10-19T10:15:12.300731Z",
     "shell.execute_reply": "2021-10-19T10:15:12.299706Z",
     "shell.execute_reply.started": "2021-10-19T10:15:12.286373Z"
    }
   },
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T10:15:12.302266Z",
     "iopub.status.busy": "2021-10-19T10:15:12.301878Z",
     "iopub.status.idle": "2021-10-19T11:03:42.959136Z",
     "shell.execute_reply": "2021-10-19T11:03:42.958293Z",
     "shell.execute_reply.started": "2021-10-19T10:15:12.302229Z"
    }
   },
   "outputs": [],
   "source": [
    "model1.fit(x = train_generator, steps_per_epoch = step_train_size, validation_data = val_generator, \n",
    "           validation_steps = step_val_size,epochs = 25, \n",
    "           callbacks = [save_best_check_point])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T11:03:42.962365Z",
     "iopub.status.busy": "2021-10-19T11:03:42.961889Z",
     "iopub.status.idle": "2021-10-19T11:03:43.084591Z",
     "shell.execute_reply": "2021-10-19T11:03:43.083774Z",
     "shell.execute_reply.started": "2021-10-19T11:03:42.962333Z"
    }
   },
   "outputs": [],
   "source": [
    "# second model so we can make predictions\n",
    "model2 = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T11:03:43.086292Z",
     "iopub.status.busy": "2021-10-19T11:03:43.086023Z",
     "iopub.status.idle": "2021-10-19T11:03:43.218975Z",
     "shell.execute_reply": "2021-10-19T11:03:43.218261Z",
     "shell.execute_reply.started": "2021-10-19T11:03:43.086258Z"
    }
   },
   "outputs": [],
   "source": [
    "##adding .jpg extension to image name in the sample submission file\n",
    "sample_submission = pd.read_csv('../input/planets-dataset/planet/planet/sample_submission.csv')\n",
    "sample_submission1 = sample_submission.copy()\n",
    "sample_submission1['image_name'] = sample_submission1['image_name'].apply(lambda x: '{}.jpg'.format(x))\n",
    "sample_submission1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T11:03:43.220724Z",
     "iopub.status.busy": "2021-10-19T11:03:43.22031Z",
     "iopub.status.idle": "2021-10-19T11:03:43.276442Z",
     "shell.execute_reply": "2021-10-19T11:03:43.275692Z",
     "shell.execute_reply.started": "2021-10-19T11:03:43.220686Z"
    }
   },
   "outputs": [],
   "source": [
    "model2.load_weights('best_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T11:03:43.27797Z",
     "iopub.status.busy": "2021-10-19T11:03:43.277729Z",
     "iopub.status.idle": "2021-10-19T11:03:43.294918Z",
     "shell.execute_reply": "2021-10-19T11:03:43.294255Z",
     "shell.execute_reply.started": "2021-10-19T11:03:43.277937Z"
    }
   },
   "outputs": [],
   "source": [
    "test1_df = sample_submission1.iloc[:40669]['image_name'].reset_index().drop('index', axis =1)\n",
    "test1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T11:03:43.297864Z",
     "iopub.status.busy": "2021-10-19T11:03:43.297549Z",
     "iopub.status.idle": "2021-10-19T11:04:04.748339Z",
     "shell.execute_reply": "2021-10-19T11:04:04.74758Z",
     "shell.execute_reply.started": "2021-10-19T11:03:43.297828Z"
    }
   },
   "outputs": [],
   "source": [
    "#initializing imagedatagenerator for the test images and also rescaling\n",
    "test_image_gen = ImageDataGenerator(rescale = 1/255)\n",
    "\n",
    "\n",
    "#creating a generator for the images found in the first test image files\n",
    "test_generator1 = test_image_gen.flow_from_dataframe(dataframe=test1_df, \n",
    "                                                directory=\"../input/planets-dataset/planet/planet/test-jpg\", \n",
    "                                                x_col=\"image_name\", y_col=None, batch_size=16, \n",
    "                                                shuffle=False, class_mode=None, target_size=(128,128))\n",
    "\n",
    "step_test_size1 = int(np.ceil(test_generator1.samples/test_generator1.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T11:08:27.931376Z",
     "iopub.status.busy": "2021-10-19T11:08:27.931124Z",
     "iopub.status.idle": "2021-10-19T11:10:16.815103Z",
     "shell.execute_reply": "2021-10-19T11:10:16.814174Z",
     "shell.execute_reply.started": "2021-10-19T11:08:27.931346Z"
    }
   },
   "outputs": [],
   "source": [
    "test_generator1.reset()\n",
    "pred1 = model2.predict(test_generator1, steps = step_test_size1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T11:10:20.8218Z",
     "iopub.status.busy": "2021-10-19T11:10:20.821538Z",
     "iopub.status.idle": "2021-10-19T11:10:28.549709Z",
     "shell.execute_reply": "2021-10-19T11:10:28.548892Z",
     "shell.execute_reply.started": "2021-10-19T11:10:20.821769Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "file_names1 = test_generator1.filenames\n",
    "\n",
    "#convert the predicted values to a dataframe and join two labels together if the probability of occurrance \n",
    "#of the label is greater than 0.5 \n",
    "pred_tags1 = pd.DataFrame(pred1)\n",
    "pred_tags1 = pred_tags1.apply(lambda x: ' '.join(np.array(labels)[x>0.5]), axis = 1)\n",
    "\n",
    "#then the result should look like this \n",
    "result1 = pd.DataFrame({'image_name': file_names1, 'tags': pred_tags1})\n",
    "result1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T11:10:35.741729Z",
     "iopub.status.busy": "2021-10-19T11:10:35.741191Z",
     "iopub.status.idle": "2021-10-19T11:10:35.755331Z",
     "shell.execute_reply": "2021-10-19T11:10:35.754467Z",
     "shell.execute_reply.started": "2021-10-19T11:10:35.741691Z"
    }
   },
   "outputs": [],
   "source": [
    "#second batch of the test dataset\n",
    "test2_df = sample_submission1.iloc[40669:]['image_name'].reset_index().drop('index', axis =1)\n",
    "test2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T11:10:44.011107Z",
     "iopub.status.busy": "2021-10-19T11:10:44.010846Z",
     "iopub.status.idle": "2021-10-19T11:10:55.188518Z",
     "shell.execute_reply": "2021-10-19T11:10:55.187744Z",
     "shell.execute_reply.started": "2021-10-19T11:10:44.011078Z"
    }
   },
   "outputs": [],
   "source": [
    "#creating a generator for the second batch of test image files\n",
    "test_generator2 = test_image_gen.flow_from_dataframe(dataframe=test2_df, \n",
    "                                                directory=\"../input/planets-dataset/test-jpg-additional/test-jpg-additional\", \n",
    "                                                x_col=\"image_name\", y_col=None, batch_size=16, \n",
    "                                                shuffle=False, class_mode=None, target_size=(128,128))\n",
    "\n",
    "step_test_size2 = int(np.ceil(test_generator2.samples/test_generator2.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T11:11:52.400001Z",
     "iopub.status.busy": "2021-10-19T11:11:52.399753Z",
     "iopub.status.idle": "2021-10-19T11:14:14.475792Z",
     "shell.execute_reply": "2021-10-19T11:14:14.47497Z",
     "shell.execute_reply.started": "2021-10-19T11:11:52.399974Z"
    }
   },
   "outputs": [],
   "source": [
    "#we reset the generator to avoid shuffling, then make prediction on the generator\n",
    "test_generator2.reset()\n",
    "pred2 = model2.predict(test_generator2, steps = step_test_size2, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T11:14:14.47774Z",
     "iopub.status.busy": "2021-10-19T11:14:14.477413Z",
     "iopub.status.idle": "2021-10-19T11:14:19.062986Z",
     "shell.execute_reply": "2021-10-19T11:14:19.06226Z",
     "shell.execute_reply.started": "2021-10-19T11:14:14.477698Z"
    }
   },
   "outputs": [],
   "source": [
    "#this is to get the filenames in the generator using the attribute .filenames\n",
    "file_names2 = test_generator2.filenames\n",
    "\n",
    "#convert the predicted values to a dataframe and join two labels together if the probability of occurrance \n",
    "#of the label is greater than 0.5\n",
    "pred_tags2 = pd.DataFrame(pred2)\n",
    "pred_tags2 = pred_tags2.apply(lambda x: ''.join(np.array(labels)[x>0.5]), axis = 1)\n",
    "\n",
    "#then the result should look like this\n",
    "result2 = pd.DataFrame({'image_name': file_names2, 'tags': pred_tags2})\n",
    "result2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T11:14:24.002465Z",
     "iopub.status.busy": "2021-10-19T11:14:24.002188Z",
     "iopub.status.idle": "2021-10-19T11:14:24.021856Z",
     "shell.execute_reply": "2021-10-19T11:14:24.02111Z",
     "shell.execute_reply.started": "2021-10-19T11:14:24.002431Z"
    }
   },
   "outputs": [],
   "source": [
    "#for the final result of the predicted tags for the test images, \n",
    "# we need to concat the first and second results in that order to avoid shuffling the index\n",
    "final_result = pd.concat([result1, result2])\n",
    "\n",
    "final_result = final_result.reset_index().drop('index', axis =1)\n",
    "\n",
    "print(final_result.shape)\n",
    "# the final result\n",
    "final_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T11:14:43.372485Z",
     "iopub.status.busy": "2021-10-19T11:14:43.372216Z",
     "iopub.status.idle": "2021-10-19T11:14:43.406107Z",
     "shell.execute_reply": "2021-10-19T11:14:43.405297Z",
     "shell.execute_reply.started": "2021-10-19T11:14:43.372454Z"
    }
   },
   "outputs": [],
   "source": [
    "#we need to remove the .jpg extension from the image_name of the last_result because from the sample submission the \n",
    "#extension was not there, we added it for easy manipulation of the data.\n",
    "final_result['image_name'] = final_result['image_name'].apply(lambda x: x[:-4])\n",
    "final_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-19T11:14:49.499699Z",
     "iopub.status.busy": "2021-10-19T11:14:49.498959Z",
     "iopub.status.idle": "2021-10-19T11:14:49.662521Z",
     "shell.execute_reply": "2021-10-19T11:14:49.661761Z",
     "shell.execute_reply.started": "2021-10-19T11:14:49.499644Z"
    }
   },
   "outputs": [],
   "source": [
    "#Finally, we save the result to a csv file using the .to_csv() method and setting the index to false.\n",
    "final_result.to_csv('submission13.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
